{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b6303ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as Data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torchvision.models.inception as inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 7770\n",
      "val len: 2230\n"
     ]
    }
   ],
   "source": [
    "label_mat = scipy.io.loadmat('../data/q3_2_data.mat')\n",
    "label_train = label_mat['trLb']\n",
    "print('train len:', len(label_train))\n",
    "label_val = label_mat['valLb']\n",
    "print('val len:', len(label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85d223c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels=[], transform = None):\n",
    "        \"\"\"\n",
    "            root_dir (string): 整个数据的路径。\n",
    "            labels(list): 图片的标签。\n",
    "            transform (callable, optional): 想要对数据进行的处理函数。\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.length = len(os.listdir(self.root_dir))\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return self.length * 3\n",
    "    def __getitem__(self, idx):\n",
    "        folder = idx//3 + 1\n",
    "        imidx = idx % 3 +1\n",
    "        folder = format(folder, '05d')\n",
    "        imgname = str(imidx) + '.jpg'\n",
    "        img_path = os.path.join(self.root_dir, folder, imgname)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if len(self.labels)!=0:\n",
    "            Label = self.labels[idx//3][0] - 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if len(self.labels)!=0:\n",
    "            sample = {'image':image,'img_path':img_path, 'Label':Label}\n",
    "        else:\n",
    "            sample = {'image':image, 'img_path':img_path}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0acc2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2980, 0.2353, 0.3569,  ..., 0.2588, 0.3373, 0.3961],\n",
      "         [0.3686, 0.2353, 0.2353,  ..., 0.2627, 0.3216, 0.3608],\n",
      "         [0.3961, 0.2471, 0.1490,  ..., 0.3647, 0.4078, 0.4353],\n",
      "         ...,\n",
      "         [0.3608, 0.3608, 0.3647,  ..., 0.2902, 0.2745, 0.2510],\n",
      "         [0.3725, 0.3725, 0.3686,  ..., 0.2667, 0.2510, 0.2353],\n",
      "         [0.3569, 0.3529, 0.3529,  ..., 0.2510, 0.2392, 0.2314]],\n",
      "\n",
      "        [[0.3137, 0.2588, 0.3804,  ..., 0.3020, 0.3765, 0.4353],\n",
      "         [0.3804, 0.2588, 0.2627,  ..., 0.3059, 0.3647, 0.4000],\n",
      "         [0.4157, 0.2667, 0.1765,  ..., 0.4078, 0.4510, 0.4784],\n",
      "         ...,\n",
      "         [0.3608, 0.3608, 0.3647,  ..., 0.2235, 0.2157, 0.2078],\n",
      "         [0.3725, 0.3725, 0.3686,  ..., 0.2000, 0.2000, 0.1922],\n",
      "         [0.3569, 0.3529, 0.3529,  ..., 0.1843, 0.1882, 0.1882]],\n",
      "\n",
      "        [[0.1843, 0.1255, 0.2392,  ..., 0.1843, 0.2706, 0.3294],\n",
      "         [0.2588, 0.1255, 0.1294,  ..., 0.1804, 0.2471, 0.2941],\n",
      "         [0.2980, 0.1412, 0.0431,  ..., 0.2824, 0.3333, 0.3608],\n",
      "         ...,\n",
      "         [0.3686, 0.3686, 0.3725,  ..., 0.1961, 0.1882, 0.1843],\n",
      "         [0.3804, 0.3804, 0.3765,  ..., 0.1725, 0.1686, 0.1686],\n",
      "         [0.3647, 0.3608, 0.3608,  ..., 0.1569, 0.1647, 0.1647]]])\n",
      "0.0\n",
      "../data/trainClips/00001/1.jpg\n"
     ]
    }
   ],
   "source": [
    "image_dataset = ActionDataset(root_dir = '../data/trainClips/', labels = label_train,transform = T.ToTensor())\n",
    "for i in range(1):\n",
    "    sample = image_dataset[i]\n",
    "    print(sample['image'].shape)\n",
    "    print(sample['Label'])\n",
    "    print(sample['img_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dde6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 3, 64, 64]) ['../data/trainClips/05009/3.jpg', '../data/trainClips/05970/3.jpg', '../data/trainClips/03846/3.jpg', '../data/trainClips/02949/3.jpg'] tensor([6., 7., 4., 3.], dtype=torch.float64)\n",
      "1 torch.Size([4, 3, 64, 64]) ['../data/trainClips/06691/3.jpg', '../data/trainClips/00537/2.jpg', '../data/trainClips/06780/2.jpg', '../data/trainClips/03155/3.jpg'] tensor([8., 0., 8., 3.], dtype=torch.float64)\n",
      "2 torch.Size([4, 3, 64, 64]) ['../data/trainClips/06603/3.jpg', '../data/trainClips/07057/3.jpg', '../data/trainClips/03539/1.jpg', '../data/trainClips/01237/3.jpg'] tensor([8., 8., 4., 1.], dtype=torch.float64)\n",
      "3 torch.Size([4, 3, 64, 64]) ['../data/trainClips/05196/1.jpg', '../data/trainClips/01912/3.jpg', '../data/trainClips/00105/3.jpg', '../data/trainClips/02259/3.jpg'] tensor([6., 2., 0., 2.], dtype=torch.float64)\n",
      "4 torch.Size([4, 3, 64, 64]) ['../data/trainClips/00468/3.jpg', '../data/trainClips/02278/2.jpg', '../data/trainClips/04430/3.jpg', '../data/trainClips/05195/3.jpg'] tensor([0., 2., 5., 6.], dtype=torch.float64)\n",
      "5 torch.Size([4, 3, 64, 64]) ['../data/trainClips/04610/3.jpg', '../data/trainClips/01179/1.jpg', '../data/trainClips/06439/1.jpg', '../data/trainClips/06880/3.jpg'] tensor([5., 1., 7., 8.], dtype=torch.float64)\n",
      "6 torch.Size([4, 3, 64, 64]) ['../data/trainClips/06004/3.jpg', '../data/trainClips/07597/1.jpg', '../data/trainClips/00470/2.jpg', '../data/trainClips/02145/2.jpg'] tensor([7., 9., 0., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "image_dataloader = DataLoader(image_dataset, batch_size = 4, shuffle = True, num_workers = 4)\n",
    "\n",
    "for i, sample in enumerate(image_dataloader):\n",
    "    sample['image'] = sample['image']\n",
    "    print(i, sample['image'].shape,sample['img_path'],sample['Label'])\n",
    "    if i >5 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf33163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_train = ActionDataset(root_dir = '../data/trainClips/', labels = label_train,transform = T.ToTensor())\n",
    "image_dataloader_train = DataLoader(image_dataset_train, batch_size = 64, shuffle = True, num_workers = 4)\n",
    "\n",
    "image_dataset_val = ActionDataset(root_dir = '../data/valClips/', labels = label_val,transform = T.ToTensor())\n",
    "image_dataloader_val = DataLoader(image_dataset_val, batch_size = 64, shuffle = True, num_workers = 4)\n",
    "\n",
    "image_dataset_test = ActionDataset(root_dir = '../data/testClips/', labels = [],transform = T.ToTensor())\n",
    "image_dataloader_test = DataLoader(image_dataset_test, batch_size = 64, shuffle = True, num_workers = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4398bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "print_every = 100\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b28feb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        N, C, H, W = x.size()\n",
    "        return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b043633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size = 7, stride = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2, stride = 2),\n",
    "            nn.Conv2d(8, 16, kernel_size = 7, stride = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2, stride = 2),\n",
    "            Flatten(),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(1936, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "08036632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 3, 64,64).type(dtype).requires_grad_(True)\n",
    "x_var = Variable(x.type(dtype))\n",
    "x_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2cd62203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataloader, num_epochs = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' %(epoch+1, num_epochs))\n",
    "        check_accuracy(fixed_model, image_dataloader_val)\n",
    "        \n",
    "        model.train() # 模型的.train()方法让模型进入训练模式，参数保留梯度，dropout层等部分正常工作。\n",
    "        for t, sample in enumerate(dataloader):\n",
    "            x_var = Variable(sample['image'])   # 取得一个batch的图像数据。\n",
    "            y_var = Variable(sample['Label'].long()) # 取得对应的标签。\n",
    "\n",
    "            scores = model(x_var)   # 得到输出。\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)   # 计算loss。\n",
    "            if (t + 1) % print_every == 0:  # 每隔一段时间打印一次loss。\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            # 三步更新参数。\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ed50a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    for t, sample in enumerate(loader):\n",
    "        x_var = Variable(sample['image'])\n",
    "        y_var = sample['Label']\n",
    "        scores = model(x_var)\n",
    "        _,preds = scores.data.max(1)\n",
    "        num_correct+=(preds.numpy()==y_var.numpy()).sum()\n",
    "        num_samples+=preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' %(num_correct, num_samples, 100*acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77fb79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(net.parameters(), lr = 0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22624f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 5\n",
      "Got 813 / 6690 correct (12.15)\n",
      "t = 100, loss = 1.7234\n",
      "t = 200, loss = 1.5962\n",
      "t = 300, loss = 1.3262\n",
      "Starting epoch 2 / 5\n",
      "Got 813 / 6690 correct (12.15)\n",
      "t = 100, loss = 1.2748\n",
      "t = 200, loss = 1.1657\n",
      "t = 300, loss = 1.3598\n",
      "Starting epoch 3 / 5\n",
      "Got 813 / 6690 correct (12.15)\n",
      "t = 100, loss = 0.8892\n",
      "t = 200, loss = 0.8928\n",
      "t = 300, loss = 1.0902\n",
      "Starting epoch 4 / 5\n",
      "Got 813 / 6690 correct (12.15)\n",
      "t = 100, loss = 1.0899\n",
      "t = 200, loss = 0.8640\n",
      "t = 300, loss = 1.0113\n",
      "Starting epoch 5 / 5\n",
      "Got 813 / 6690 correct (12.15)\n",
      "t = 100, loss = 1.0518\n",
      "t = 200, loss = 1.0053\n",
      "t = 300, loss = 0.7456\n",
      "Got 3105 / 6690 correct (46.41)\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(54321)\n",
    "net.cpu()\n",
    "net.apply(reset)\n",
    "net.train()\n",
    "train(net, loss_fn, optimizer, dataloader= image_dataloader_train, num_epochs=5)\n",
    "check_accuracy(net, image_dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f9448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
